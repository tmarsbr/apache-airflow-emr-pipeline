# ğŸš€ Apache Airflow + AWS EMR Data Pipeline

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um pipeline completo de ETL (Extract, Transform, Load) para processamento de dados de voos utilizando **Apache Airflow** e **AWS EMR** com **Apache Spark**. O pipeline processa um dataset de 5.8 milhÃµes de registros de voos (~565MB) convertendo de CSV para formato Parquet particionado otimizado para anÃ¡lises.

### ğŸ¯ Demanda do Projeto

**Contexto**: Processar grandes volumes de dados de voos de forma escalÃ¡vel e automatizada.

**Requisitos**:
- âœ… Processamento de dataset com 5.8M+ registros de voos
- âœ… ConversÃ£o de CSV para Parquet com compressÃ£o Snappy
- âœ… Particionamento por ano/mÃªs/dia para otimizaÃ§Ã£o de queries
- âœ… OrquestraÃ§Ã£o automatizada com Apache Airflow
- âœ… Processamento distribuÃ­do com AWS EMR e Spark
- âœ… Monitoramento e logs detalhados
- âœ… GestÃ£o de custos e recursos na nuvem

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Apache        â”‚    â”‚   AWS EMR       â”‚    â”‚   Amazon S3     â”‚
â”‚   Airflow       â”‚    â”‚   (Spark)       â”‚    â”‚   (Storage)     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ ETL DAG     â”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Spark Jobs  â”‚ â”‚â”€â”€â”€â–¶â”‚ â”‚ Parquet     â”‚ â”‚
â”‚ â”‚ Scheduler   â”‚ â”‚    â”‚ â”‚ Processing  â”‚ â”‚    â”‚ â”‚ Partitioned â”‚ â”‚
â”‚ â”‚ Monitoring  â”‚ â”‚    â”‚ â”‚ Distributed â”‚ â”‚    â”‚ â”‚ Optimized   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
   OrquestraÃ§Ã£o            Processamento              Armazenamento
   & Monitoramento         DistribuÃ­do                & Analytics
```

### ğŸ“Š Fluxo de Dados

1. **Origem**: `s3://bkt-athena-class-podacademy-meu/athena/flights/flights.csv` (564.96 MB)
2. **Processamento**: EMR Cluster (1 Master m4.xlarge + 2 Workers m4.large)
3. **Destino**: `s3://bkt-athena-meu/processed/flights/` (Parquet particionado)

## ğŸ› ï¸ Stack TecnolÃ³gica

### Core Technologies
- **ğŸ Apache Airflow 2.8.2**: OrquestraÃ§Ã£o e agendamento
- **âš¡ Apache Spark 3.4.1**: Processamento distribuÃ­do
- **â˜ï¸ AWS EMR 6.15.0**: Cluster gerenciado para Big Data
- **ğŸ“¦ Amazon S3**: Armazenamento de dados
- **ğŸ³ Docker Compose**: ContainerizaÃ§Ã£o do Airflow

### AWS Services
- **EMR**: Elastic MapReduce para Spark clusters
- **S3**: Object storage para dados e logs
- **EC2**: InstÃ¢ncias para cluster EMR
- **IAM**: GestÃ£o de permissÃµes e roles
- **VPC**: Rede privada e seguranÃ§a

### Python Libraries
- **boto3 1.28.57**: SDK AWS para Python
- **apache-airflow-providers-amazon 8.7.1**: Providers AWS para Airflow
- **pyspark**: Interface Python para Spark

## ğŸ“ Estrutura do Projeto

```
apache_airflow_emr/
â”œâ”€â”€ README.md                          # DocumentaÃ§Ã£o principal
â”œâ”€â”€ EMR_ETL_GUIDE.md                   # Guia tÃ©cnico detalhado
â”œâ”€â”€ setup_emr_roles.sh                 # Script de configuraÃ§Ã£o IAM
â”œâ”€â”€ airflow-docker/
â”‚   â”œâ”€â”€ docker-compose.yml             # ConfiguraÃ§Ã£o Airflow
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ aws_credentials            # Credenciais AWS (gitignored)
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ etl_airlines_emr_spark.py  # DAG principal do pipeline
â”‚   â”œâ”€â”€ logs/                          # Logs do Airflow
â”‚   â”œâ”€â”€ plugins/                       # Plugins customizados
â”‚   â””â”€â”€ requirements.txt               # DependÃªncias Python
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md                # DocumentaÃ§Ã£o da arquitetura
    â”œâ”€â”€ troubleshooting.md             # Guia de resoluÃ§Ã£o de problemas
    â””â”€â”€ performance.md                 # AnÃ¡lise de performance
```

## ğŸš€ Quick Start

### 1. PrÃ©-requisitos

```bash
# AWS CLI v2.x
aws --version

# Docker & Docker Compose
docker --version
docker-compose --version

# Python 3.8+
python3 --version

# Git
git --version
```

### 2. ConfiguraÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/apache_airflow_emr.git
cd apache_airflow_emr

# Configure as credenciais AWS
cp airflow-docker/config/aws_credentials.example airflow-docker/config/aws_credentials
# Edite com suas credenciais

# Configurar IAM roles (executar uma vez)
chmod +x setup_emr_roles.sh
./setup_emr_roles.sh

# Iniciar Airflow
cd airflow-docker
docker-compose up -d
```

### 3. ExecuÃ§Ã£o

1. **Acesse o Airflow**: http://localhost:8080 (admin/admin)
2. **Habilite o DAG**: `etl_airlines_emr_spark`
3. **Execute manualmente** ou aguarde o agendamento
4. **Monitore** os logs e status na interface

## ğŸ’¡ Desafios TÃ©cnicos e SoluÃ§Ãµes

### ğŸ”§ Problema 1: Compatibilidade de InstÃ¢ncias
**Desafio**: InstÃ¢ncias m5.large nÃ£o disponÃ­veis na regiÃ£o/zona selecionada.

**SoluÃ§Ã£o**: 
- MudanÃ§a de regiÃ£o de `sa-east-1` para `us-east-1`
- Uso de instÃ¢ncias `m4.xlarge` (master) + `m4.large` (workers)
- ConfiguraÃ§Ã£o VPC obrigatÃ³ria para famÃ­lia m4

### ğŸ”§ Problema 2: ConfiguraÃ§Ã£o VPC
**Desafio**: Erro "instance type m4.xlarge can only be used in a VPC".

**SoluÃ§Ã£o**:
```python
# ConfiguraÃ§Ã£o VPC no EMR
'Ec2SubnetId': 'subnet-099582e55cb06f04c',  # us-east-1a
'EmrManagedMasterSecurityGroup': 'sg-xxx',
'EmrManagedSlaveSecurityGroup': 'sg-yyy'
```

### ğŸ”§ Problema 3: PermissÃµes IAM
**Desafio**: Roles EMR sem permissÃµes adequadas para EC2.

**SoluÃ§Ã£o**:
```bash
# EMR Service Role
aws iam attach-role-policy \
    --role-name EMR_DefaultRole \
    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole

# EMR EC2 Instance Profile
aws iam attach-role-policy \
    --role-name EMR_EC2_DefaultRole \
    --policy-arn arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforEC2Role
```

### ğŸ”§ Problema 4: Capacidade de Zona
**Desafio**: "Insufficient capacity" em us-east-1d.

**SoluÃ§Ã£o**: MigraÃ§Ã£o para zona `us-east-1a` com capacidade disponÃ­vel.

### ğŸ”§ Problema 5: Erro de Tipo de Dados no Spark
**Desafio**: Script tentando usar `year(DEPARTURE_TIME)` em coluna INTEGER.

**SoluÃ§Ã£o**:
```python
# Usar colunas existentes YEAR, MONTH, DAY
if "YEAR" in columns and "MONTH" in columns and "DAY" in columns:
    df_partitioned = df \
        .withColumnRenamed("YEAR", "year") \
        .withColumnRenamed("MONTH", "month") \
        .withColumnRenamed("DAY", "day")
```

## ğŸ“ˆ Resultados e Performance

### ğŸ“Š MÃ©tricas de Processamento
- **Registros processados**: 5,819,079 voos
- **Tamanho original**: 564.96 MB (CSV)
- **Formato final**: Parquet com compressÃ£o Snappy
- **Particionamento**: Por ano/mÃªs/dia (otimizaÃ§Ã£o de queries)
- **Tempo de processamento**: ~3-4 minutos
- **Cluster**: 1 Master + 2 Workers (16 vCores total)

### ğŸ’° OtimizaÃ§Ã£o de Custos
- **Cluster EMR**: TerminaÃ§Ã£o automÃ¡tica apÃ³s conclusÃ£o
- **InstÃ¢ncias**: m4.large/xlarge (custo-benefÃ­cio)
- **Storage**: S3 Standard com lifecycle policies
- **Monitoramento**: CloudWatch para controle de custos

## ğŸ” Monitoramento e Logs

### Airflow UI
- **DAG Status**: ExecuÃ§Ã£o e histÃ³rico
- **Task Logs**: Logs detalhados por task
- **XCom**: ComunicaÃ§Ã£o entre tasks
- **Gantt Chart**: Timeline de execuÃ§Ã£o

### EMR Logs
```bash
# Logs no S3
s3://bkt-athena-meu/emr-logs/j-CLUSTERID/
â”œâ”€â”€ containers/          # Logs dos containers Spark
â”œâ”€â”€ hadoop-logs/         # Logs do Hadoop
â””â”€â”€ spark-logs/          # Logs de aplicaÃ§Ãµes Spark
```

### Spark UI
- **Jobs**: Status e mÃ©tricas de jobs
- **Stages**: Breakdown de execuÃ§Ã£o
- **Storage**: Uso de memÃ³ria e cache
- **Environment**: ConfiguraÃ§Ã£o do cluster

## ğŸ§ª Testes e ValidaÃ§Ã£o

### ValidaÃ§Ã£o de Dados
```python
# VerificaÃ§Ã£o de integridade
print(f"ğŸ“Š Total de registros: {df.count()}")
print(f"ğŸ“… Anos: {df.select('YEAR').distinct().count()}")
print(f"ğŸ—“ï¸ Meses: {df.select('MONTH').distinct().count()}")

# Schema validation
df.printSchema()
```

### Testes de Pipeline
- âœ… Conectividade S3
- âœ… CriaÃ§Ã£o de cluster EMR
- âœ… ExecuÃ§Ã£o de jobs Spark
- âœ… Particionamento correto
- âœ… CompressÃ£o Parquet
- âœ… TerminaÃ§Ã£o de recursos

## ğŸš¨ Troubleshooting

### Problemas Comuns

**1. Erro de Credenciais AWS**
```bash
# Verificar configuraÃ§Ã£o
aws sts get-caller-identity
aws s3 ls s3://seu-bucket/
```

**2. Cluster EMR nÃ£o inicia**
```bash
# Verificar logs de bootstrap
aws emr describe-cluster --cluster-id j-CLUSTERID
```

**3. Job Spark falha**
```bash
# Baixar logs de erro
aws s3 cp s3://bucket/emr-logs/cluster/containers/stderr.gz - | gunzip
```

### Monitoramento Proativo
- CloudWatch Alarms para custos
- NotificaÃ§Ãµes SNS para falhas
- Dashboards personalizados

## ğŸ”® PrÃ³ximos Passos

### Melhorias TÃ©cnicas
- [ ] **Delta Lake**: Versionamento e ACID transactions
- [ ] **Glue Catalog**: Metastore centralizado
- [ ] **Athena Integration**: Queries SQL diretas
- [ ] **Apache Iceberg**: Table format otimizado

### OtimizaÃ§Ãµes
- [ ] **Auto Scaling**: Ajuste dinÃ¢mico de clusters
- [ ] **Spot Instances**: ReduÃ§Ã£o de custos
- [ ] **Caching**: Redis para metadados
- [ ] **Partitioning Strategy**: OtimizaÃ§Ã£o avanÃ§ada

### GovernanÃ§a
- [ ] **Data Quality**: ValidaÃ§Ãµes automÃ¡ticas
- [ ] **Lineage**: Rastreamento de dados
- [ ] **Security**: Encryption at rest/transit
- [ ] **Compliance**: GDPR/LGPD readiness

## ğŸ‘¥ ContribuiÃ§Ã£o

### Como Contribuir
1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

### Guidelines
- CÃ³digo bem documentado
- Testes unitÃ¡rios
- Logs detalhados
- Tratamento de erros

## ğŸ“ Contato

**Desenvolvedor**: Tiago  
**LinkedIn**: [seu-linkedin](https://linkedin.com/in/seu-perfil)  
**Email**: seu-email@exemplo.com  
**GitHub**: [seu-usuario](https://github.com/seu-usuario)

---

## ğŸ“‹ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

## ğŸ† Agradecimentos

- **Apache Software Foundation** pelo Airflow e Spark
- **AWS** pela infraestrutura cloud robusta
- **Comunidade Open Source** pelo suporte e documentaÃ§Ã£o

---

*Projeto desenvolvido como demonstraÃ§Ã£o de habilidades em Engenharia de Dados, Big Data e Cloud Computing.*